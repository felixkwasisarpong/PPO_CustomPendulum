# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ajM_jdzjiGt930dlprxxFfMmbss5OiUc
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import gym
import matplotlib.pyplot as plt

# Set device (CPU or GPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class ReplayBuffer:
    def __init__(self):
        self.states = []
        self.actions = []
        self.rewards = []
        self.log_probs = []
        self.values = []
        self.advantages = []

    def store(self, state, action, reward, log_prob, value):
        self.states.append(state)
        self.actions.append(action)
        self.rewards.append(reward)
        self.log_probs.append(log_prob)
        self.values.append(value)

    def compute_advantages(self, gamma, lam, next_value):
        returns = []
        advantages = []
        gae = 0
        for i in reversed(range(len(self.rewards))):
            delta = self.rewards[i] + gamma * next_value - self.values[i]
            gae = delta + gamma * lam * gae
            advantages.insert(0, gae)
            next_value = self.values[i]
            returns.insert(0, gae + self.values[i])
        self.advantages = advantages
        self.returns = returns

    def clear(self):
        self.states = []
        self.actions = []
        self.rewards = []
        self.log_probs = []
        self.values = []
        self.advantages = []